<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CPS: Cognitive Trust in Human-Autonomous Vehicle Interactions</AwardTitle>
<AwardEffectiveDate>04/01/2018</AwardEffectiveDate>
<AwardExpirationDate>03/31/2020</AwardExpirationDate>
<AwardAmount>175000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jonathan Sprinkle</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This goal of this research is to create new techniques for advancing our understanding of the role of trust within human-autonomous vehicle interactions and assisting in the design of safe and trustworthy autonomy into future vehicles. We are witnessing accelerating technological advances in autonomous vehicles. As the degree of autonomy of vehicles increases and the nature of human-autonomy interactions becomes more complex, key questions that need to be asked are how to ensure safety and trust in human-autonomous vehicle interactions. On the one hand, high-profile incidents make clear the risks from "overtrust" or over-reliance on autonomous vehicles. On the other hand, "undertrust" may cause the neglect or under-utilization of automation. This work will be integrated into the graduate and undergraduate education on cyber-physical systems, as well as various Science, Technology, Engineering and Mathematics (STEM) outreach programs for K-12 students.&lt;br/&gt;&lt;br/&gt;The approach is to develop languages and algorithms for formally expressing and reasoning about trust in human-autonomous vehicle interactions. This includes new models that can represent a human's trust in autonomous vehicles, together with new formal methods that can use these models in a tractable manner to verify trust requirements. The key innovations include new methods to measure trust based on multi-modal sensing of human cognitive and physiological states, new methods to express and verify trust-based specifications, and new methods to explain trust-based decisions in human-autonomy interactions. If successful, this research will allow the formalization of trust in human-autonomous vehicle interactions and the design of autonomous vehicles that establish appropriate levels of trust.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/07/2018</MinAmdLetterDate>
<MaxAmdLetterDate>03/07/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1755784</AwardID>
<Investigator>
<FirstName>Lu</FirstName>
<LastName>Feng</LastName>
<EmailAddress>lf9u@virginia.edu</EmailAddress>
<StartDate>03/07/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Virginia Main Campus</Name>
<CityName>CHARLOTTESVILLE</CityName>
<ZipCode>229044195</ZipCode>
<PhoneNumber>4349244270</PhoneNumber>
<StreetAddress>P.O.  BOX 400195</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
</Institution>
<ProgramElement>
<Code>026y</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
</Award>
</rootTag>
