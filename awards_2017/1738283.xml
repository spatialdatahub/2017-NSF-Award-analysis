<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>I-Corps: Mobile Augmented Reality</AwardTitle>
<AwardEffectiveDate>04/01/2017</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cindy WalkerPeach</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this I-Corps project is catalyzing the shift from mobile to spatial computing through enabling Augmented Reality (AR) technology.  AR has a broad impact across many use cases such as instruction, visualization, and entertainment.  AR offers an intuitive visualization that decreases the cognitive overhead for the user, thus providing an environment with less manufacturing mistakes, better-visualized parts, or real-time data visualizations for example.  Such technology enhances the abilities of people by showing the relevant information when it is needed to the user. This context-aware visualization tool offers a personalized experience in a way that brings digital content into the physical world in an intuitive, spatially consistent manner. This growing new technology has the potential to change how people interact with digital content in the physical world.&lt;br/&gt;&lt;br/&gt;This I-Corps project addresses the problem of estimating a partially observable three-dimensional manifold in conjunction with a full 6-degree of freedom pose from inertial measurements and sequential two-dimensional luminescent representations of semi-static observations - a fundamental problem for Augmented Reality (AR).  Inertial observations alone provide minimal uncertainty for up to a tenth of a second using commercially available and ubiquitous hardware, thus limiting the accuracy pose estimation and, for practical long-term applications, necessitating visual input to be jointly fused in.  This project focuses on ubiquitous handheld computing platforms, inducing resource constraint considerations for both accuracy and human interface experiences.  Further computational considerations need to be made for enabling parallel application-specific processes, thus further limiting available resources.</AbstractNarration>
<MinAmdLetterDate>03/29/2017</MinAmdLetterDate>
<MaxAmdLetterDate>03/29/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1738283</AwardID>
<Investigator>
<FirstName>Roman</FirstName>
<LastName>Lubynsky</LastName>
<EmailAddress>rml@mit.edu</EmailAddress>
<StartDate>03/29/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<ProgramElement>
<Code>8023</Code>
<Text>I-Corps</Text>
</ProgramElement>
</Award>
</rootTag>
