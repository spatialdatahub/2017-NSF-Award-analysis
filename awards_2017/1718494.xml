<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Capacity via Symmetry</AwardTitle>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardAmount>514176</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Richard Brown</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Information theory studies the fundamental laws that govern information processing systems. For instance, the Shannon Capacity of a noisy channel is the largest rate (in bits per channel use) that bits can be reliably communicated. Information theory has had an enormous impact on how information is acquired, processed, compressed, and transmitted. Examples include channel coding and data compression, both of which are used extensively in Internet and cellular communications. This project focuses on connections between performance and codebook symmetry. One part focuses on using symmetry to help low-complexity decoders achieve near-optimum performance for codes relevant to 5G cellular standards. This project will also train several graduate students, hence an important broader impact of this project is the production of highly-trained workers in electrical engineering and computer science.&lt;br/&gt;&lt;br/&gt;Many theoretical results in information theory use random codebooks to encode messages. Researchers have long sought families of deterministic algebraic codes that provably achieve capacity. In a recent breakthrough, the PI and his coauthors showed that sequences of sufficiently symmetric codes achieve capacity on the binary erasure channel. Since Reed-Muller codes satisfy the required symmetry condition, we now know that such a code family was discovered by Muller in 1954, only 6 years after Shannon's introduction of channel capacity! The project focuses on whether symmetric codebooks can be used in more general settings to approach information-theoretic limits. In particular, the goals are to determine: (i) How general is the phenomenon of capacity via symmetry? (ii) What performance gains can be achieved in practice by exploiting symmetries? (iii) Can symmetry be utilized to approach the information-theoretic limits of other problems?</AbstractNarration>
<MinAmdLetterDate>06/28/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/28/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1718494</AwardID>
<Investigator>
<FirstName>Galen</FirstName>
<LastName>Reeves</LastName>
<EmailAddress>galen.reeves@duke.edu</EmailAddress>
<StartDate>06/28/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Henry</FirstName>
<LastName>Pfister</LastName>
<EmailAddress>henry.pfister@duke.edu</EmailAddress>
<StartDate>06/28/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
</Institution>
<ProgramElement>
<Code>7797</Code>
<Text>COMM &amp; INFORMATION FOUNDATIONS</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
</ProgramReference>
</Award>
</rootTag>
