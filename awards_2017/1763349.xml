<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Medium: Collaborative Research: Foundations of Fair Data Analysis</AwardTitle>
<AwardEffectiveDate>07/01/2018</AwardEffectiveDate>
<AwardExpirationDate>06/30/2022</AwardExpirationDate>
<AwardAmount>63168</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy J. Kimbrel</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Machine learning algorithms increasingly make or inform critical decisions that affect peoples' every day lives. For instance, algorithms make decisions pertaining to hiring, college admissions, credit card and mortgage approvals, sentencing and parole of the incarcerated, first-responder deployment, and what advertisements and search results a user sees on the internet. An attractive feature is that these algorithms can efficiently process large amounts of data in making these decisions, thus hopefully improving economic and social efficiency. Because such decisions are so consequential, their fairness has become a matter of increasing concern. It has been argued that automation, by removing the human element, guarantees fairness, but this is not so -- several empirical studies have demonstrated that automation is no panacea. Further, the reasons for unfairness and discrimination can be complex and non-obvious. This project will study the frictions that may cause unfairness in algorithmic decision making, and the costs of mitigating unfairness -- that is, quantitative trade-offs between fairness and other desiderata, including accuracy, computational efficiency, and economic efficiency. &lt;br/&gt;&lt;br/&gt;Specifically, this project will study frictions to fairness arising from several factors. There may not be sufficient data about minority populations. There can be feedback loops arising from the fact that observations can only be made on an individual if a risky action is taken, e.g., the person is granted a loan, or hired. Decision makers can be myopic, choosing to maximize short-term gains rather than exploring riskier options that may pay off in the long run. Economic frictions include self-confirming equilibria---differing subjective perceptions of opportunities leading to choices by individuals and communities which sustain those perceptions, and competition among classifiers (for example, credit agencies) leading to less accurate qualifiers in equilibrium. Finally, the problem of finding fair and accurate classifiers can be computationally intractable. This project will seek ways to mitigate the unfairness arising from these frictions. It will study the cost of incentivizing myopic agents to explore and examine the short-term costs of such incentives, and their long-term impact on fairness. It will also seek to design computationally tractable classifiers that achieve provably good approximations for fairness and accuracy.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/12/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/12/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1763349</AwardID>
<Investigator>
<FirstName>Mallesh</FirstName>
<LastName>Pai</LastName>
<EmailAddress>Mallesh.Pai@rice.edu</EmailAddress>
<StartDate>06/12/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>William Marsh Rice University</Name>
<CityName>Houston</CityName>
<ZipCode>770051827</ZipCode>
<PhoneNumber>7133484820</PhoneNumber>
<StreetAddress>6100 MAIN ST</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
</Institution>
<ProgramElement>
<Code>2878</Code>
<Text>SPECIAL PROJECTS - CCF</Text>
</ProgramElement>
<ProgramElement>
<Code>7796</Code>
<Text>ALGORITHMIC FOUNDATIONS</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7932</Code>
<Text>COMPUT GAME THEORY &amp; ECON</Text>
</ProgramReference>
</Award>
</rootTag>
