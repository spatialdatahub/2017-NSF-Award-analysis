<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>S&amp;AS: FND: COLLAB: Learning Manipulation Skills Using Deep Reinforcement Learning with Domain Transfer</AwardTitle>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardAmount>308000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project develops new methods of using deep reinforcement learning to solve real world robotics problems. The project focuses on robotic manipulation tasks such as grasping, opening doors, helping out in the home, performing repairs aboard Navy ships, etc. The key operation in all of the above is the ability for the robot to reliably manipulate objects, parts, or tools with its hands in order to perform a task. The project leverages deep reinforcement learning: a new approach to robotic learning that is capable of learning both perceptual features and control policies simultaneously. This project could have important benefits for a variety of practical applications including: explosive ordnance disposal for our military, materials handling aboard Navy ships, dexterous robotic assistants for NASA astronauts in space, assistive technologies that could help seniors age in place longer, better capabilities for handling radioactive materials during nuclear cleanup, assistance for ergonomically challenging tasks in manufacturing, and general assistance in the office and the home.&lt;br/&gt;&lt;br/&gt;This research investigates novel deep reinforcement learning approaches for robotic grasping and manipulation that work well in previously unseen, unstructured environments and compose end-to-end tasks from simpler sub-task controllers. The research is built on two main results from research team's recent work, the deep learning approach to grasping and domain adaptation methods for deep neural networks. The research is guided by the following three key ideas: 1) learning in simulation and then using domain transfer techniques to adapt the solutions to reality; 2) simplifying learning for visuomotor control by using planning to estimate the value function; and 3) using symbolic task and motion planning to perform end-to-end tasks by sequencing learned controllers and planned arm/hand motions. The research team performs extensive evaluations to ensure that the system is able to perform novel instances of a task, e.g., those in a context that the robot has not seen before.</AbstractNarration>
<MinAmdLetterDate>08/16/2017</MinAmdLetterDate>
<MaxAmdLetterDate>04/13/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1724237</AwardID>
<Investigator>
<FirstName>Kate</FirstName>
<LastName>Saenko</LastName>
<EmailAddress>saenko@bu.edu</EmailAddress>
<StartDate>08/16/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<ProgramElement>
<Code>039Y</Code>
<Text>S&amp;AS - Smart &amp; Autonomous Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>046Z</Code>
<Text>S&amp;AS - Smart &amp; Autonomous Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
</ProgramReference>
</Award>
</rootTag>
