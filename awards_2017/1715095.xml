<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Searching for Answers through Iterative Feedback</AwardTitle>
<AwardEffectiveDate>08/15/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardAmount>492023</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James French</SignBlockName>
</ProgramOfficer>
<AbstractNarration>In current web search engines, the response to a query is typically a series of pages that contain ranked results (search engine result pages or SERPs). The increasing use of mobile search places a premium on the use of the limited display space that is available. Similarly, voice-based search, where both questions and answers are done by voice recognition and speech generation, is becoming more common and also creates a limitation on the interaction bandwidth between the system and the user. In these situations, the ability to deliver more precise answers to a broad range of questions, rather than a ranked display of results, becomes critical. If a search system can return a ranked list of possible answers instead of documents, and a search environment may limit the user-system bandwidth, this leads to the following important research question that is the focus of this proposal -- what is the most effective way to present and interact with a ranked list of answers, where the goal is to identify one or more satisfactory answers as quickly as possible. Understanding this problem and discovering solutions to it will have a large impact on the future development of search engines.&lt;br/&gt;&lt;br/&gt;This project will work on four research tasks: (a) develop and evaluate iterative relevance feedback models for answers; (b) develop and evaluate interactive summarization techniques for answers; (c) develop and evaluate finer-grained feedback approaches for answers; (d) develop and evaluate a conversation-based model for answer retrieval. This project will be the first to study methods and models for interacting with ranked lists of answers. Many researchers are developing neural models for the factoid question-answering task, but this effort is one of just a few looking at the problem of finding non-factoid answers in passages of documents. The experience gained from developing neural models for this complex task provides the background for the unique tasks and approaches described in this proposal, which address the key, but previously ignored, issue of how we make effective use of ranked lists of answers to interact with users and improve the results from neural answer retrieval models. The later part of the project will address the use of conversational models in search, which is also becoming increasingly important but has not yet been studied.</AbstractNarration>
<MinAmdLetterDate>08/04/2017</MinAmdLetterDate>
<MaxAmdLetterDate>09/12/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1715095</AwardID>
<Investigator>
<FirstName>W. Bruce</FirstName>
<LastName>Croft</LastName>
<EmailAddress>croft@cs.umass.edu</EmailAddress>
<StartDate>08/04/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<ProgramElement>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
