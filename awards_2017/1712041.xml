<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:  Statistical Inference Using Random Forests and Related Methods</AwardTitle>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardAmount>119802</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yong Zeng</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project seeks to develop methods to quantify uncertainty in machine learning algorithms and to incorporate machine learning and statistical inference. Machine learning has been enormously successful at using data to make predictions; it is used in an extensive range of applications from handwriting recognition to high frequency trading to driverless cars and personalized medicine. However, while machine learning algorithms make good predictions, they tell humans very little about how those predictions were arrived at: What were the important factors? How did they affect the prediction? They also don't distinguish predictions for which there is a lot of information about the probability of different outcomes (even if that covers a wide range) from those where very little information is available. For example, a machine learning algorithm may very accurately predict whether a person is likely to develop diabetes, but provides little if any information regarding how that person might lower his or her risk. This project will build on initial mathematical theory to develop methods to explain how Random Forests arrive at their predictions and how statistically confident those predictions are, and produce ways to link machine learning methods to other statistical models.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This project seeks to develop methods to quantify uncertainty in machine learning algorithms and to incorporate machine learning and statistical inference. The project will extend on a theoretical framework representing Random Forests as U-statistics to produce a practical implementation of statistical uncertainty quantification in machine learning. In particular, it will improve on methods to estimate sample variability in Random Forest predictions, develop computationally efficient screening tools for covariate and interaction selection, and incorporate ensemble methods as non-parametric terms in partially-linear models while retaining statistical inference via a modified boosting algorithm. These methods will be demonstrated on a citizen science data base in ornithology and in various biomedical applications.</AbstractNarration>
<MinAmdLetterDate>07/19/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/19/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1712041</AwardID>
<Investigator>
<FirstName>Lucas</FirstName>
<LastName>Mentch</LastName>
<EmailAddress>lkm31@pitt.edu</EmailAddress>
<StartDate>07/19/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pittsburgh</Name>
<CityName>Pittsburgh</CityName>
<ZipCode>152132303</ZipCode>
<PhoneNumber>4126247400</PhoneNumber>
<StreetAddress>University Club</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
</Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7454</Code>
<Text>MSPA-INTERDISCIPLINARY</Text>
</ProgramElement>
<ProgramReference>
<Code>8007</Code>
<Text>BioMaPS</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
</Award>
</rootTag>
