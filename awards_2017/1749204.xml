<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Safe and Efficient Robot Learning from Demonstration in the Real World</AwardTitle>
<AwardEffectiveDate>06/01/2018</AwardEffectiveDate>
<AwardExpirationDate>05/31/2023</AwardExpirationDate>
<AwardAmount>137302</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Reid Simmons</SignBlockName>
</ProgramOfficer>
<AbstractNarration>General purpose robots are poised to enter the home and workplace in unprecedented numbers in coming years, but face the significant challenge of customization - the ability to perform user-specified tasks in many different unstructured environments. In response to this need, robot learning from demonstration (LfD) has emerged as a paradigm that allows users to quickly and naturally program robots by simply showing them how to perform a task, rather than by writing code. This methodology aims to allow non-expert users to program robots, as well as communicate embodied knowledge that is difficult to translate into formal code. However, current state-of-the-art LfD algorithms are not yet ready for widespread deployment, as they are often unreliable, need too much data, and are designed to learn in a single session in a laboratory setting.  This work addresses these issues to help enable future robots to perform important tasks ranging from in-home elderly care to reconfigurable manufacturing.&lt;br/&gt;&lt;br/&gt;Specifically, this work identifies three significant technical improvements to current LfD algorithms that are needed before they can be deployed in the real world: the need for safety guarantees, the ability to learn from very limited amounts of data, and the ability to continually improve in an ongoing, life-long fashion.  A formal theory of safe LfD is developed, along with practical algorithms that provide strong probabilistic lower bounds on agent performance.  Algorithmic efficiency is addressed via a re-examining of common statistical assumptions (such as independent and identically distributed data) and through the use of multimodal side-information, such as natural language and gaze.  Finally, active learning strategies and modeling of human beliefs are used to enable interactive, continual learning.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/23/2018</MinAmdLetterDate>
<MaxAmdLetterDate>03/23/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1749204</AwardID>
<Investigator>
<FirstName>Scott</FirstName>
<LastName>Niekum</LastName>
<EmailAddress>sniekum@cs.utexas.edu</EmailAddress>
<StartDate>03/23/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
</Award>
</rootTag>
