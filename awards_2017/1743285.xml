<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Workshop Support to Encourage Student Investigation of Gesture and Dialog</AwardTitle>
<AwardEffectiveDate>06/01/2017</AwardEffectiveDate>
<AwardExpirationDate>05/31/2018</AwardExpirationDate>
<AwardAmount>14345</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana D. Korelsky</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The connection between humans and their machines has never been more significant or more fundamental to our culture and our activities of daily living. While more prevalent in younger generations, humans of all ages are becoming increasingly dependent and engaged by devices and the human/machine relationship is in a state of extremely rapid change and growing importance to the national economy. Smartphones, robotic vacuum cleaners, web-enabled kitchen appliances, and virtual personal assistants are all around us and competing for our attention and our discretionary spending. In fact, we are engaging much more in a dialog with our machines, than ever before, eschewing the prior modalities of one-way command/response. Gestural interfaces have become so commonplace that many toddlers have begun to expect bi-directional interaction from inanimate objects. Much of this advancement has been driven by technological prowess and the race toward what is possible, rather than careful human-centric analysis and design. This is largely due to the complex interdisciplinary issues that are raised and the difficulties in bringing together the right collection of expertise to address them. The Workshop on Adaptive-Shot Learning for Gesture Understanding and Production, a scientific workshop on the intersection of gesture, machine learning and embodied intelligence, seeks to increase interest and activities in the interdisciplinary study of gesture and dialog for human/machine interaction through technical exchange and interaction which can lead to scientific advancements with high economic payoff and deep impact on well-being. Advancing the theoretical bases of these fields and their intersection can have enormous societal impact and will stimulate careful, multi-dimensional study of the field, promoting a diversity of thought and, ultimately, greater satisfaction for human users.&lt;br/&gt;&lt;br/&gt;The goals of the Workshop include several things. First, increasing interest in the intersection of the fields of gesture recognition, verbal and non-verbal dialog, and embodied intelligence is key. This will result in a richer body of knowledge which, in turn, will result in more responsive, natural, and effective human/machine interfaces. Second, increasing the engagement of this younger generation of device users in the research and teaching of how these fields overlap is important. Familiar devices are important tools to engage new potential scientists and philosophers in the excitement of new discoveries. Finally, attracting a broad audience that cross-cuts the diverse fields of study of relevance to these new interaction modalities to enable outside-the-box thinking. The Workshop is organized by a diverse group of researchers from computer science, engineering, technology, psychology, and design and is held in Washington, DC, in connection to the IEEE Automatic Face and Gesture Recognition Conference, May 30-June 3, 2017. Travel grants supported by this grant are being offered, specifically targeting junior grad students with novel ideas, to join the established researchers to present their ideas in an informal setting. The diverse panel of organizers will recruit applicants to a gentle competition for these travel awards to encourage excellent submissions. This will achieve the goals, further educational attainment, and advance diversity of thought.</AbstractNarration>
<MinAmdLetterDate>06/05/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/05/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1743285</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Voyles</LastName>
<EmailAddress>rvoyles@purdue.edu</EmailAddress>
<StartDate>06/05/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Juan</FirstName>
<LastName>Wachs</LastName>
<EmailAddress>jpwachs@purdue.edu</EmailAddress>
<StartDate>06/05/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
</Institution>
<ProgramElement>
<Code>7367</Code>
<Text>Cyber-Human Systems (CHS)</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7556</Code>
<Text>CONFERENCE AND WORKSHOPS</Text>
</ProgramReference>
</Award>
</rootTag>
