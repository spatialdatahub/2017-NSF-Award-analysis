<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>I-Corps: Multi-modal Robot Skins for Adaptive Human-Machine Interfaces</AwardTitle>
<AwardEffectiveDate>01/01/2017</AwardEffectiveDate>
<AwardExpirationDate>02/28/2018</AwardExpirationDate>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cindy WalkerPeach</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this I-Corps project will consist of creating higher performance human-machine interfaces, with wide-ranging applications not only in robotics, but also in manufacturing, healthcare, and intelligent consumer products. Increasing human-machine collaboration by adding cost-effective and customizable sensory perception, for instance touch sensing, to future machines will have an impact to their safety when operating around people, and will enhance their usability, productivity, and level of personalization. Consumers at large will benefit from product interfaces that are more intuitive and easier to learn and use. Numerous companies and government labs will also benefit from the commercialization of technology resulting from this project, as it will help retrofit their existing infrastructure with robotic skin patches to make it safer and more productive.&lt;br/&gt;&lt;br/&gt;This I-Corps project will undertake commercialization feasibility research for 'Electronic Skin' technologies based on multi-sensory perception of humans interacting physically with machines, through sensing touch pressure, acceleration, temperature and proximity.  Using in-house fabricated tactile sensors embedded in flexible substrates, combined with other types of commercial off-the shelf sensors, this project develops modular systems that can be networked and scaled in large numbers. Numerous sensor components are 3D printed, and can be retrofitted onto existing machinery, such as robots, automated production units, appliances in a cost effective manner. Furthermore, the human-machine interface software of the system involves novel learning algorithms that can adapt to user preferences, decrease the task completion time, and the level of expertise required by users. The adaptive software learns to adjust the human-machine parameters in real-time, according to interaction results, and can take into account sensor degradation over time, user fatigue, and other persistent and costly technical challenges that have limited the widespread adoption of this technology in the past.</AbstractNarration>
<MinAmdLetterDate>12/14/2016</MinAmdLetterDate>
<MaxAmdLetterDate>12/14/2016</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1713741</AwardID>
<Investigator>
<FirstName>Dan</FirstName>
<LastName>Popa</LastName>
<EmailAddress>dan.popa@louisville.edu</EmailAddress>
<StartDate>12/14/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Louisville Research Foundation Inc</Name>
<CityName>Louisville</CityName>
<ZipCode>402021959</ZipCode>
<PhoneNumber>5028523788</PhoneNumber>
<StreetAddress>The Nucleus</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<StateCode>KY</StateCode>
</Institution>
<ProgramElement>
<Code>8023</Code>
<Text>I-Corps</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
</Award>
</rootTag>
