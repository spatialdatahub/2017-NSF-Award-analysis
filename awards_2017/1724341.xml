<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>S&amp;AS: INT: Autonomous Multi-Robot Visual Monitoring for Urban, Agricultural, and Natural Resource Management</AwardTitle>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardAmount>1000000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project develops technologies to improve natural resource monitoring systems.  Specifically, this project investigates how teams of smart and autonomous aerial robots equipped with visual sensors can monitor vegetation health over extended spatial and temporal scales.  It addresses the fundamental issues of i) multi-robot collaboration, ii) adaptation of robot trajectories according to the quality of collected visual data, iii) networked decision making under several conflicting constraints, and iv) learning planning and control at real-world dynamic environments.  The project further investigates how these four tasks can work seamlessly with each other, under autonomous and real-time operation.  In addition to improving vegetation monitoring, the outcomes of this project may benefit several other application domains, including habitat monitoring, border control, forest fire tracking and search-and-rescue operations. Additionally, the project involves several hands-on procedures that are expected to attract undergraduate student participation and enable outreach to K-12 students.&lt;br/&gt;&lt;br/&gt;This research addresses the theoretical and technical challenges in order to enable autonomous multi-robot visual monitoring of critical natural resources.  A critical step in this effort is to introduce novel algorithmic frameworks that can enable networks of smart and autonomous aerial robots to detect and adapt to observed phenomena, while satisfying multiple - often conflicting - time-varying constraints and mission specifications.  To achieve this, the project contributes to three main areas. i) Adaptive visual sensing with focus on the analysis of visual data that can automatically adapt to the environment and the computational constraints. ii) Autonomous aerial robot navigation, developing reliable and energy-efficient autonomous aerial robot navigation strategies under resource constraints. iii) System-level decision-making and adaptation, which will focus on general reasoning, decision-making and control schemes for adaptive resource allocation under the real-time constraints.  The project seamlessly merges individual contributions into the proposed Adaptive Resource Monitoring (ARM) system.  ARM is cognizant of its environmental, technical and ethical constraints, and issues goal-oriented tasks for each agent.  ARM possesses the ability to reflect upon past decisions and reinforce advantageous ones, and is driven by knowledge-rich models and methods. The individual components and the overall system are tested through a rigorous evaluation plan, starting with individual modules and leading up to a system-level evaluation in the application domain.</AbstractNarration>
<MinAmdLetterDate>08/17/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/17/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1724341</AwardID>
<Investigator>
<FirstName>Amit</FirstName>
<LastName>Roy Chowdhury</LastName>
<EmailAddress>amitrc@ece.ucr.edu</EmailAddress>
<StartDate>08/17/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Anastasios</FirstName>
<LastName>Mourikis</LastName>
<EmailAddress>mourikis@ee.ucr.edu</EmailAddress>
<StartDate>08/17/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>George</FirstName>
<LastName>Jenerette</LastName>
<EmailAddress>darrel.jenerette@ucr.edu</EmailAddress>
<StartDate>08/17/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Konstantinos</FirstName>
<LastName>Karydis</LastName>
<EmailAddress>kkarydis@ece.ucr.edu</EmailAddress>
<StartDate>08/17/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Qi</FirstName>
<LastName>Zhu</LastName>
<EmailAddress>qzhu@northwestern.edu</EmailAddress>
<StartDate>08/17/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Riverside</Name>
<CityName>RIVERSIDE</CityName>
<ZipCode>925210217</ZipCode>
<PhoneNumber>9518275535</PhoneNumber>
<StreetAddress>Research &amp; Economic Development</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>039Y</Code>
<Text>S&amp;AS - Smart &amp; Autonomous Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>046Z</Code>
<Text>S&amp;AS - Smart &amp; Autonomous Systems</Text>
</ProgramReference>
</Award>
</rootTag>
