<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Medium: Data Driven Biomechanically Accurate Modeling of Human Gait on Unconstrained Terrain</AwardTitle>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardAmount>1182466</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim P. Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Modeling human gait parametrically, efficiently and accurately is an open and challenging problem with many applications such as ergonomics, animation, biomechanics, rehabilitation, physical therapy, virtual reality and entertainment.  Gait is a complex process, because numerous human joint degrees-of-freedom have to be simultaneously coordinated and adapted to varying types of terrain, types of gait and related kinematics and dynamics.  As a consequence, no general-purpose models of gait kinematics on unconstrained complex terrain exist, and even basic kinematic gait databases and related ground forces that can form the basis for developing such models do not provide accurate information.  Most gait data are collected by the commonly used surface marker systems, which suffer from soft tissue artifacts and are not sufficient for a full understanding of gait kinematics.  Developing a parameterized human gait for unconstrained terrain will have broad impact on the fields of virtual reality, next generation shoe design, computer animation, workplace safety, ergonomics, sports medicine, biomedical and clinical research to aid people with gait abnormalities.  Project outcomes, including algorithms and datasets, will ultimately be incorporated in the curricula of many fields including computer science and biomedical engineering, and will result in a better informed community of people working on gait modeling and its applications.&lt;br/&gt;&lt;br/&gt;Using recently purchased novel all-terrain gait treadmills, motion capture, video cameras, ground reaction forces based on force plates, and high speed ultrasonic images of knee and ankle joints, the PI and his team have collected gait data from multiple people.  The first goal of this project is to integrate all of this data by exploiting novel computer vision and multimodal optimization algorithms to produce an anatomically correct human skeleton with human specific joints, human shape, ground reaction forces and kinematic data.  The second goal is to develop an efficient, accurate, and general purpose parameterized model of human gait kinematics and biomechanics capable of reproducing the data, and more importantly, predicting and generalizing human specific gait for new types of terrain.  The gait variations to be modeled range from very slow shuffling to normal walking on a variety of terrain conditions such as inclined and declined slope, left and right cross-slope, and up and down stairs.</AbstractNarration>
<MinAmdLetterDate>08/16/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/16/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1703883</AwardID>
<Investigator>
<FirstName>Mubbasir</FirstName>
<LastName>Kapadia</LastName>
<EmailAddress>mubbasir.kapadia@rutgers.edu</EmailAddress>
<StartDate>08/16/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kang</FirstName>
<LastName>Li</LastName>
<EmailAddress>kl419@rci.rutgers.edu</EmailAddress>
<StartDate>08/16/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Dimitris</FirstName>
<LastName>Metaxas</LastName>
<EmailAddress>dnm@cs.rutgers.edu</EmailAddress>
<StartDate>08/16/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
</Institution>
<ProgramElement>
<Code>7367</Code>
<Text>Cyber-Human Systems (CHS)</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
