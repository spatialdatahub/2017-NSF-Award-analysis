<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Medium: An Interaction Manager for Language and Force Exhanges in Human-Robot Physical Collaboration</AwardTitle>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardAmount>1048618</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Reid Simmons</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project will develop a computational and data-driven framework for a robot assistant to collaborate with humans in everyday tasks that involve physical interaction, such as handing over or moving an object together. Using models learned from observing humans perform such tasks, the robot will engage in back-and-forth communication, where turns can be both spoken utterances and force exchanges. Robots that can collaborate to perform physical tasks could provide assistance in a variety of settings, such as performing household chores, supporting the elderly to remain independent, and assisting human workers on the factory floor.&lt;br/&gt;&lt;br/&gt;The transformative idea of the proposal is to generalize the methodology of dialog processing to include physical interaction. The fundamental challenge is how to bridge the gap between the symbolic processing of language and the low-level control of force exchanges. The concept of interaction primitives (IPs) is introduced to model physical interactions. Further, a planning and execution framework in the form of an interaction manager is proposed. The proposed interaction manager broadens the traditional dialogue modeling paradigm so that information can flow from more abstract to lower levels, and vice versa: language affects physical interaction, and physical interaction affects what is said. To build the interaction manager, a targeted data collection where humans perform tasks of interest will be performed. Since physical interaction data is invariably sparse, statistical learning on the data will be complemented by model-based generalizations, allowing robots to collaborate with humans in highly variable and unstructured environments. The research will inform new course development, and involve several undergraduate and graduate students.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/25/2017</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1705058</AwardID>
<Investigator>
<FirstName>Barbara</FirstName>
<LastName>DiEugenio</LastName>
<EmailAddress>bdieugen@uic.edu</EmailAddress>
<StartDate>07/25/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Milos</FirstName>
<LastName>Zefran</LastName>
<EmailAddress>mzefran@uic.edu</EmailAddress>
<StartDate>07/25/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Chicago</Name>
<CityName>CHICAGO</CityName>
<ZipCode>606124305</ZipCode>
<PhoneNumber>3129962862</PhoneNumber>
<StreetAddress>809 S. Marshfield Avenue</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
