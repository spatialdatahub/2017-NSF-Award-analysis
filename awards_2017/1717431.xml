<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI:Small: Unsupervised Discriminatively-Generative Learning:</AwardTitle>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Great success has been achieved in obtaining powerful discriminative classifiers via supervised training where humans provide manual annotations to the training data. Unsupervised learning, in which the input data is not accompanied with task-specific annotations, is of great importance since a large number of tasks have no to little supervision. However, it still remains to be one of the most difficult problems in machine learning. A typical unsupervised learning task learns effective generative representations for highly structured data such as images, videos, speech, and text. Existing generative models for unsupervised learning are often constrained by their simplified assumptions, while existing discriminative models for supervised learning are of limited generation capabilities. This project develops a new introspective machine learning framework that greatly enhances and expands the power of both generation and discrimination for a single model. The outcome of the project, introspective generative/discriminative learning, significantly improves the learning capabilities of the existing algorithms by building stronger computational models for a wide range of fields including computer vision, machine learning, cognitive science, computational linguistics, and data mining. &lt;br/&gt;&lt;br/&gt;This research investigates a new machine learning framework, introspective generative/discriminative learning (IGDL), which attains a single generator/discriminator capable of performing both generation and classification.  The IGDL generator is itself a discriminator, capable of introspection --- being able to self-evaluate the difference between its generated samples and the given training data. When followed by iterative discriminative learning, desirable properties of modern discriminative classifiers such as convolutional neural networks (CNN) can be directly inherited by the IGDL generator. Moreover, the discriminator aspect of IGDL also produces competitive results in fully supervised classification by using self-generated new data (called pseudo-negatives) to enhance the classification performance against adversarial samples. The training process of IGDL is carried out using a two-step synthesis-by-classification algorithm via efficient backpropagation. Effective stochastic gradient descent Monte Carlo sampling processes for IGDL training are studied. Across three key areas in machine learning including unsupervised, semi-supervised, and fully-supervised learning, IGDL produces competitive results in a wide range of applications including texture synthesis, object modeling, and image classification.</AbstractNarration>
<MinAmdLetterDate>07/27/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1717431</AwardID>
<Investigator>
<FirstName>Zhuowen</FirstName>
<LastName>Tu</LastName>
<EmailAddress>zhuowen.tu@gmail.com</EmailAddress>
<StartDate>07/27/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930621</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
