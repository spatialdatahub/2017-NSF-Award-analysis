<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPS: Medium: Enabling Multimodal Sensing, Real-time Onboard Detection and Adaptive Control for Fully Autonomous Unmanned Aerial Systems</AwardTitle>
<AwardEffectiveDate>10/01/2017</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jonathan Sprinkle</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to investigate a low-cost and energy-efficient hardware and software system to close the loop between processing of sensor data, semantically high-level detection and trajectory generation in real-time. To safely integrate Unmanned Aerial Vehicles into national airspace, there is an urgent need to develop onboard sense-and-avoid capability. While deep neural networks (DNNs) have significantly improved the accuracy of object detection and decision making, they have prohibitively high complexity to be implemented on small UAVs. Moreover, existing UAV flight control approaches ignore the nonlinearities of UAVs and do not provide trajectory assurance. &lt;br/&gt;&lt;br/&gt;The research thrusts of this project are: (i) FPGA implementation of DNNs: both fully connected and convolutional layers of deep (convolutional) neural networks will be trained using (block-)circulant matrix and implemented using custom designed universal Fast Fourier Transform kernels on FPGA. This research thrust will enable efficient implementation of DNNs, reducing memory and computation complexity from O(N2) to O(N) and O(NlogN), respectively; (ii) autonomous detection and perception for onboard sense-and-avoid: existing regional detection neural networks will be extended to work with images taken from different angles, and multi-modal sensor inputs; (iii) real-time waypoint and trajectory generation - an integrated trajectory generation and feedback control scheme for steering under-actuated vehicles through desired waypoints in 3D space will be developed. For efficient implementation and hardware reuse, both detection and control problems will be formulated and solved using DNNs with (block-)circulant weight matrix. Deep reinforcement learning models will be investigated for waypoint generation and to assign artificial potential around the obstacles to guarantee a safe distance. The fundamental research results will enable onboard computing, real-time detection and control, which are cornerstones of autonomous and next-generation UAVs.</AbstractNarration>
<MinAmdLetterDate>08/07/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1739748</AwardID>
<Investigator>
<FirstName>Qinru</FirstName>
<LastName>Qiu</LastName>
<EmailAddress>qiqiu@syr.edu</EmailAddress>
<StartDate>08/07/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Amit</FirstName>
<LastName>Sanyal</LastName>
<EmailAddress>aksanyal@akrobotix.com</EmailAddress>
<StartDate>08/07/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Senem</FirstName>
<LastName>Velipasalar</LastName>
<EmailAddress>svelipas@syr.edu</EmailAddress>
<StartDate>08/07/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jian</FirstName>
<LastName>Tang</LastName>
<EmailAddress>jtang02@syr.edu</EmailAddress>
<StartDate>08/07/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yanzhi</FirstName>
<LastName>Wang</LastName>
<EmailAddress>yanzhiwang@northeastern.edu</EmailAddress>
<StartDate>08/07/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Syracuse University</Name>
<CityName>SYRACUSE</CityName>
<ZipCode>132441200</ZipCode>
<PhoneNumber>3154432807</PhoneNumber>
<StreetAddress>OFFICE OF SPONSORED PROGRAMS</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<ProgramElement>
<Code>039Y</Code>
<Text>S&amp;AS - Smart &amp; Autonomous Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>046Z</Code>
<Text>S&amp;AS - Smart &amp; Autonomous Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
</Award>
</rootTag>
