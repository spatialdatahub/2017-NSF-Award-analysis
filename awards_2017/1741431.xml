<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: IA: Distributed Semi-Supervised Training of Deep Models and Its Applications in Video Understanding</AwardTitle>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardAmount>662431</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Aidong Zhang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project investigates semi-supervised training of deep neural network models using large-scale labeled and unlabeled data in a distributed fashion. Deep neural networks have recently been widely deployed in artificial intelligence and related scientific fields, largely attributing to well-labeled big datasets and improved computing capabilities. However, the unlabeled data, which is often bigger, is inherently ruled out by the prevailing supervised training of the deep models. It is indeed highly challenging to model the unlabeled parts of many recent and emerging datasets, which are often unstructured and distributed over different nodes of a network (e.g., the videos captured by a camera network). This project aims to explore how to effectively use the unlabeled and distributed data to complement the discriminative cues of the labeled data, to jointly learn accurate and robust deep models. The research seamlessly unifies machine learning, computer vision, and parallel computing, and fosters unique interdisciplinary research and education programs for the graduate and undergraduate students.&lt;br/&gt;&lt;br/&gt;Despite the progress on semi-supervised learning and deep learning, the confluence of these two is mostly studied on a small scale in single-machine environment. However, many new datasets easily grow beyond the computation or even storage capacity of a single machine. Hence, it becomes a pressing need to investigate the semi-supervised learning of deep models on parallel computing platforms. To better account for this scenario, this project develops improved network architectures to facilitate the parallel training, and the training procedure developed adaptively switches between synchronized and asynchronized modes for optimal efficiency. The main idea is to incorporate a parametric distribution to the neural network and use covariate matching to coordinate the network behaviors across different machines. The researchers also explore a novel application, extreme-scale spatial-temporal action annotation of video sequences, to benchmark the algorithms and frameworks in this project.</AbstractNarration>
<MinAmdLetterDate>08/29/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/29/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1741431</AwardID>
<Investigator>
<FirstName>Boqing</FirstName>
<LastName>Gong</LastName>
<EmailAddress>bgong@icsi.berkeley.edu</EmailAddress>
<StartDate>08/29/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mubarak</FirstName>
<LastName>Shah</LastName>
<EmailAddress>shah@crcv.ucf.edu</EmailAddress>
<StartDate>08/29/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Liqiang</FirstName>
<LastName>Wang</LastName>
<EmailAddress>lwang@cs.ucf.edu</EmailAddress>
<StartDate>08/29/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Central Florida</Name>
<CityName>ORLANDO</CityName>
<ZipCode>328168005</ZipCode>
<PhoneNumber>4078230387</PhoneNumber>
<StreetAddress>4000 CNTRL FLORIDA BLVD</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
</Institution>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
</Award>
</rootTag>
