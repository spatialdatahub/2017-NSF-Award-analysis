<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CIF: New Structure-Exploiting and Memory-Efficient Methods for Large-Scale Optimization and Data Analysis</AwardTitle>
<AwardEffectiveDate>07/01/2018</AwardEffectiveDate>
<AwardExpirationDate>06/30/2020</AwardExpirationDate>
<AwardAmount>175000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Richard Brown</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Large-scale optimization methods have been paramount to the successes of recent applications of machine learning and data analysis in a wide variety of domains. At the same time, certain structural properties of statistical models, such as sparsity or low-rank structure, have proven to be crucial for obtaining meaningful and accurate results in high dimensions. In addition to being highly scalable to large datasets, some optimization algorithms have the desirable property that they directly promote the aforementioned valuable structural properties of models. This project involves developing, analyzing, and implementing novel optimization algorithms that have such beneficial structure-exploiting and also memory-efficiency properties. This project directly involves the mentoring of graduate students, as well as integration of research results into an undergraduate level machine learning course and a graduate level course in optimization and statistical learning.&lt;br/&gt;&lt;br/&gt;The foundation for this project is the Frank-Wolfe Method, a particular structure-exploiting first-order gradient optimization algorithm, and the related methodology of in-face directions. In-face directions automatically promote well-structured near-optimal solutions and have encouraging memory-efficiency properties. This research will investigate conditions whereby methods with in-face directions, as applied to convex relaxations of matrix completion and more general atomic norm regularization problems, are guaranteed to have a low memory footprint. Furthermore, this project will extend the reach of methods that incorporate in-face directions to new problem classes, including non-smooth objective functions, non-convex objective functions, and stochastic gradient estimates. The proposed optimization framework and in-face methodology applies very generally, and has potential for broader impact in several areas, including recommender systems, bioinformatics, customer segmentation, sentiment analysis, and medical imaging.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/29/2018</MinAmdLetterDate>
<MaxAmdLetterDate>01/29/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1755705</AwardID>
<Investigator>
<FirstName>Paul</FirstName>
<LastName>Grigas</LastName>
<EmailAddress>pgrigas@berkeley.edu</EmailAddress>
<StartDate>01/29/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947045940</ZipCode>
<PhoneNumber>5106428109</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>7797</Code>
<Text>COMM &amp; INFORMATION FOUNDATIONS</Text>
</ProgramElement>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
</Award>
</rootTag>
