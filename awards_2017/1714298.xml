<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Decision Making in Autonomous Machines</AwardTitle>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardAmount>138000</AwardAmount>
<AwardInstrument>
<Value>Fellowship</Value>
</AwardInstrument>
<Organization>
<Code>04010000</Code>
<Directorate>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<LongName>SBE Off Of Multidisciplinary Activities</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Josie S. Welkom</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This award was provided as part of NSF's Social, Behavioral and Economic Sciences Postdoctoral Research Fellowships (SPRF) program. The goal of the SPRF program is to prepare promising, early career doctoral-level scientists for scientific careers in academia, industry or private sector, and government. SPRF awards involve two years of training under the sponsorship of established scientists and encourage Postdoctoral Fellows to perform independent research. NSF seeks to promote the participation of scientists from all segments of the scientific community, including those from underrepresented groups, in its research programs and activities; the postdoctoral period is considered to be an important level of professional development in attaining this goal. Each Postdoctoral Fellow must address important scientific questions that advance their respective disciplinary fields. The Directorate of Social, Behavioral and Economic Sciences offers postdoctoral research fellowships to provide opportunities for recent doctoral graduates to obtain additional training, to gain research experience under the sponsorship of established scientists, and to broaden their scientific horizons beyond their undergraduate and graduate training. This postdoctoral fellowship award supports a rising scholar in the field of psychology investigating how people perceive the morality of autonomous machines (AM), and whether people are willing to delegate moral responsibility to AM. For thousands of years, morality was believed to be unique to humans. However, the rise of AM challenges this uniqueness. As autonomous machines become more sophisticated, they are able to make decisions with moral importance in medicine, military and driving. This research investigates whether people are willing to extend moral agency to machines and allow them to make decisions when lives are at stake. This research advances social science to keep pace with technological advancement, investigates the roots of moral judgment, and also helps reveal whether morality can be shared amongst humans and autonomous machines.&lt;br/&gt;&lt;br/&gt;This research project has three objectives. The first objective is assessing the perceived moral status of autonomous machines. Are robots seen as morally responsible in the same way as people, and if not, in what ways are they morally deficient? The second objective is assessing the role of perceived mind in the moral status of autonomous machines. What kind of minds are autonomous robots seen to have, and does this mind determine their moral status? This objective is relevant for human agents as well as for autonomous machines. Doing so, we investigate for the first time which mental capacities people want moral agents to have. The third objective is assessing whether acceptance of robots as moral deciders depends on their advantage as deciders and on whether or not they are fully autonomous. The research investigates these objectives, using both large-scale surveys in which participants rate their reaction to humans and AM making moral decisions, and laboratory studies providing further validation and using measures other than self-report. Finally, the research investigates how professionals, such as medical practitioners, respond to the possibility of AM making some of the hard decisions they usually make.</AbstractNarration>
<MinAmdLetterDate>07/06/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/06/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1714298</AwardID>
<Investigator>
<FirstName>Yochanan</FirstName>
<LastName>Bigman</LastName>
<EmailAddress/>
<StartDate>07/06/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kurt</FirstName>
<LastName>Gray</LastName>
<EmailAddress/>
<StartDate>07/06/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Bigman                  Yochanan       E</Name>
<CityName>Jerusalem</CityName>
<ZipCode/>
<PhoneNumber/>
<StreetAddress/>
<CountryName>Israel</CountryName>
<StateName/>
<StateCode/>
</Institution>
<ProgramElement>
<Code>040Y</Code>
<Text>(SPRF-FR) SBE Postdoctoral Res</Text>
</ProgramElement>
</Award>
</rootTag>
