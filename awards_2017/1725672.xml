<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SPX: Collaborative Research: Eat your Wheaties: Multi-Grain Compilers for Parallel Builds at Every Scale</AwardTitle>
<AwardEffectiveDate>08/15/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardAmount>200000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Title: SPX: Collaborative Research: Multi-Grain Compilers for Parallel Builds at Every Scale&lt;br/&gt;&lt;br/&gt;Modern software development practices at companies such as Google and Facebook have led to compilation -- the process of transforming source programs into executable programs -- becoming a significant, time-consuming,  resource-intensive process.  Unfortunately, even state of the art compilers and build systems do not do a good job of exploiting emerging, high-performance, highly-parallel hardware, so software development is hampered by the still-slow process of compilation.  This project aims to develop new techniques to speed up the process of compilation. The intellectual merits are designing new compiler internals, algorithms, and schedulers to enable compilers to take advantage of modern hardware capabilities. The project's broader significance and importance are that the process of compilation undergirds virtually every aspect of modern software, and hence modern life: speeding up compilation enables any type of software to be developed more quickly, providing new features to users and more quickly squashing potentially catastrophic bugs.&lt;br/&gt;&lt;br/&gt;The project revolves around three main thrusts. First, the PIs are developing new representations for compiler internals that better fit the memory hierarchy of modern machines, eschewing pointer-based representations for dense representations. We are designing techniques to allow programmers to write their compiler passes at a high level while automatically converting them to use the dense representation. Second, the PIs are designing new algorithms to optimize compiler passes. These are transformations of internal compiler algorithms to promote locality (by combining passes that operate on similar portions of a program) and to enhance parallelism (by eliminating unnecessary synchronization between passes). Finally, the PIs are creating new scheduling techniques to allow the new highly-parallel compiler algorithms to be effectively mapped to the parallel and distributed hardware on which modern build systems execute.</AbstractNarration>
<MinAmdLetterDate>08/01/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/01/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1725672</AwardID>
<Investigator>
<FirstName>Milind</FirstName>
<LastName>Kulkarni</LastName>
<EmailAddress>milind@purdue.edu</EmailAddress>
<StartDate>08/01/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
</Institution>
<ProgramElement>
<Code>042Y</Code>
<Text>SPX: Scalable Parallelism in t</Text>
</ProgramElement>
<ProgramReference>
<Code>026Z</Code>
<Text>NSCI: National Strategic Computing Initi</Text>
</ProgramReference>
</Award>
</rootTag>
