<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: ConnotationNet: Modeling Non-Literal Meaning in Context</AwardTitle>
<AwardEffectiveDate>09/15/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardAmount>499838</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Donald T. Langendoen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The major goal of this research is to develop a new computational framework to recover and reason about a wide range of connotative meanings in language, i.e., why something is written and how it will affect the readers. This contrasts with the vast majority of previous research on semantic processing, where the primary focus has been on understanding the denotational meaning of language, i.e., what is written in text. This research will create new computational solutions to a wide range of tasks that require understanding non-literal meaning in text, including societally important challenges such as automatic detection and revision of biases in modern literature and media that can work against minorities and underrepresented groups.&lt;br/&gt;&lt;br/&gt;This research will develop Connotation Frames as a new representation formalism to organize a variety of connotative implications associated with a particular choice of a predicate. This representation will substantially extend the existing resources of frame semantics, which has focused primarily on denotational meanings, by introducing new typed relations to encode various aspects of connotative meanings. Capitalizing on recent advances in distributional representation of words and phrases, this research will develop algorithms that can infer connotation frames from a large-scale natural language corpus, which reflects how connotative meanings arise from how people use language in context. The learned representations will be organized as ConnotationNet, an evolving broad-coverage connotation lexicon for words, frames, and phrases. Knowledge encoded in this lexicon will then be used for document-level text understanding, where partially present information in text will be combined with the rich connotative knowledge stored in ConnotationNet to infer the complete the document-level connotation of given text. In parallel, this research will seek new language generation models that can learn to revise or compose text with the desired connotative effects with specific focus on unwanted biases in modern literature and media against underrepresented groups.</AbstractNarration>
<MinAmdLetterDate>07/27/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1714566</AwardID>
<Investigator>
<FirstName>Yejin</FirstName>
<LastName>Choi</LastName>
<EmailAddress>yejin@cs.washington.edu</EmailAddress>
<StartDate>07/27/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
