<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBE-RCUK: CompCog: Modeling the Development of Phonetic Representations</AwardTitle>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardAmount>520058</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty H. Tuller</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Listeners' processing of speech is tuned to their native language. For example, Japanese listeners categorizing English [l] and [r] do not rely on the same aspects of the speech signal that native English listeners do. This project uses computational models to investigate how children develop language-specific perceptual strategies. A better understanding of this perceptual learning process could lead to better diagnosis and treatment of developmental language impairments that have a perceptual basis and can provide insight into the difficulties that listeners face when learning a second language in adulthood. Building computational models of how children learn their native language from the speech around them can also lead to improved speech technology for low-resource languages (languages that are not spoken by many people in the world or that lack digital resources such as large-scale, annotated databases), ultimately leading to systems that learn more effectively using little or no transcribed audio. Such systems could become important tools for documenting and analyzing endangered and minority languages and could help make speech technology more universally available.&lt;br/&gt;&lt;br/&gt;A series of simulations tests the hypothesis that children's processing of speech can become specialized for their native language through a process of dimension learning that does not rely on knowledge of sound categories. Two models that use dimension learning are proposed, drawing on representation learning methods that have performed well in low-resource automatic speech recognition, where extensive labeled training data are not available. The first model relies on temporal information as a proxy for sound category knowledge, while the second model relies on top-down information from similar words, which infants have been shown to use. Each model is trained on speech recordings from a particular language and is evaluated on its ability to predict how adults and infants with that language background discriminate sounds. The research will yield new methods for training and testing cognitive models of language with naturalistic speech recordings and has the potential to significantly impact theories of how and when children learn about the sounds of their native language.</AbstractNarration>
<MinAmdLetterDate>06/22/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/22/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1734245</AwardID>
<Investigator>
<FirstName>Naomi</FirstName>
<LastName>Feldman</LastName>
<EmailAddress>nhf@umd.edu</EmailAddress>
<StartDate>06/22/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland College Park</Name>
<CityName>COLLEGE PARK</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
</Institution>
<ProgramElement>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>1698</Code>
<Text>DS - Developmental Sciences</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>PERCEPTION, ACTION &amp; COGNITION</Text>
</ProgramElement>
<ProgramReference>
<Code>003Z</Code>
<Text>SBE-RCUK MOU</Text>
</ProgramReference>
</Award>
</rootTag>
