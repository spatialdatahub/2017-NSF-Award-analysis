<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Addressing the memory bottleneck in deep neural networks in cloud platforms</AwardTitle>
<AwardEffectiveDate>01/01/2018</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardAmount>224586</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will consist in defining the way toward an ultra-fast and energy efficient accelerator for Machine Learning applications deployed on cloud computing. The merging of cloud computing and Machine Learning is shaping our everyday life experience. Examples of applications running on the cloud and exploiting Machine Learning algorithms include data mining, natural language processing and pattern recognition. These three together represent cognitive computing and, due to a vast and growing number of APIs for developers, it is becoming easier to access the computational power of the cloud and develop new applications. This new computation potential is used by businesses to connect data and find patterns valuable for commerce or to improve cybersecurity.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project will define a new kind of hardware accelerator, able to speed up cognitive computation by orders of magnitude while reducing energy consumption compared with state-of-the-art processors. The proposed technology is fast and energy efficient, but can be prone to low precision and temperature variation sensitivity. During Phase I, the company will define the hardware accelerator at the system level, optimizing the design for ultra-high speed and sufficient precision to carry out the cognitive computation required. At the same time, the effect of temperature variation and noise will be minimized through improved design. Finally, the energy consumption of the new designs will be estimated and compared with the overall performance of state-of-the-art competitive architectures.</AbstractNarration>
<MinAmdLetterDate>12/27/2017</MinAmdLetterDate>
<MaxAmdLetterDate>12/27/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1747360</AwardID>
<Investigator>
<FirstName>Farnood</FirstName>
<LastName>Merrikh Bayat</LastName>
<EmailAddress>farnoodmb@mentium.tech</EmailAddress>
<StartDate>12/27/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Mentium Technologies Inc.</Name>
<CityName>Goleta</CityName>
<ZipCode>931175494</ZipCode>
<PhoneNumber>8056176245</PhoneNumber>
<StreetAddress>2208 Pacific Coast Dr</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8033</Code>
<Text>Hardware Software Integration</Text>
</ProgramReference>
</Award>
</rootTag>
