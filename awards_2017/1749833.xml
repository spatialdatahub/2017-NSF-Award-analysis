<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER:Towards Perceptual Agents That See and Reason Like Humans</AwardTitle>
<AwardEffectiveDate>06/01/2018</AwardEffectiveDate>
<AwardExpirationDate>05/31/2023</AwardExpirationDate>
<AwardAmount>545586</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Recent advancements in computer vision systems have enabled their widespread deployment in areas like social media, healthcare, robotics, and ecology, among many others. While such applications hold exceptional promise for improving our well-being and advancing scientific discovery, the ubiquity of these intelligent systems presents new technical, social, and cultural challenges for their wide-scale adoption. This project leads an integrated effort of research, teaching, and outreach to address some of these challenges. The project develops architectures that are substantially more accurate and capable of extracting detailed information from perceptual data across different modalities. An emphasis of this work is to develop computer vision systems that can reason about data in ways that are interpretable by humans. This project also promotes diversity, engages high school, undergraduate, and graduate students in research activities, and fosters collaborations with industry and researchers in areas such as ecology and biology through workshops.&lt;br/&gt;&lt;br/&gt;This research explores new directions that improve the capabilities of visual perception and reasoning systems for analyzing image data, spatio-temporal data, and depth data. The research develops a novel class of graph-based and factorized architectures for 3D shape and spatio-temporal analysis that provide better tradeoffs between computational cost, memory overhead, and accuracy than existing models. The research develops weakly supervised techniques for learning shape and motion representations from large amounts of unlabeled data. The research also develops a novel class of techniques for transforming visual data to semantic representations such as attributes, natural language, and symbolic programs. These techniques will improve the interpretability of machine learning models and enable collaborative learning and inference between humans and AI agents.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/01/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/01/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1749833</AwardID>
<Investigator>
<FirstName>Subhransu</FirstName>
<LastName>Maji</LastName>
<EmailAddress>smaji@cs.umass.edu</EmailAddress>
<StartDate>06/01/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
</Award>
</rootTag>
