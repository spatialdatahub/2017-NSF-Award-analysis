<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SaTC: CORE: Large: Collaborative: Accountable Information Use: Privacy and Fairness in Decision-Making Systems</AwardTitle>
<AwardEffectiveDate>06/01/2017</AwardEffectiveDate>
<AwardExpirationDate>05/31/2022</AwardExpirationDate>
<AwardAmount>154751</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Susanne Wetzel</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Increasingly, decisions and actions affecting people's lives are determined by automated systems processing personal data.  Excitement about these systems has been accompanied by serious concerns about their opacity and the threats that they pose to privacy, fairness, and other values.  Recognizing these concerns, the investigators seek to make real-world automated decision-making systems accountable for privacy and fairness by enabling them to detect and explain violations of these values.  The technical work is informed by, and applied to, online advertising, healthcare, and criminal justice, in collaboration with and as advised by domain experts. &lt;br/&gt;&lt;br/&gt;Addressing privacy and fairness in decision systems requires providing formal definitional frameworks and practical system designs.  The investigators provide new notions of privacy and fairness that deal with both protected information itself and proxies for it, while handling context-dependent, normative definitions of violations.  A fundamental tension they address pits the access given to auditors of a system against the system owners' intellectual property protections and the confidentiality of the personal data used by the system.  The investigators decompose such auditing into stages, where the level of access granted to an auditor is increased when potential (but not explainable) violations of privacy or fairness are detected. Workshops and public releases of code and data amplify the investigators' interactions with policy makers and other stakeholders.  Their partnerships with outreach organizations encourage diversity.</AbstractNarration>
<MinAmdLetterDate>05/18/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/18/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1704985</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Tschantz</LastName>
<EmailAddress>mct@icsi.berkeley.edu</EmailAddress>
<StartDate>05/18/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>International Computer Science Institute</Name>
<CityName>Berkeley</CityName>
<ZipCode>947044115</ZipCode>
<PhoneNumber>5106662900</PhoneNumber>
<StreetAddress>1947 CENTER ST STE 600</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
