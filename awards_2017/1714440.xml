<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Algorithms and Theoretical Foundations for Approximate Bayesian Inference in Machine Learning</AwardTitle>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardAmount>497115</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Aidong Zhang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Over the last two decades Bayesian models have become central in machine learning. Bayesian models often hypothesize latent (non-observed) variables with explanatory or predictive power toward observed phenomena. The challenge is to infer the state of these variables or a belief over that state from observed data. For example, one might try to infer a user's preferences from observations about their own behavior and the behavior of other users. The goal of this project is to develop general approximate inference algorithms that work across large families of Bayesian models so that solutions can be widely reused. The algorithmic work will be complemented by developing a learning theory for approximate Bayesian inference in machine learning. The theoretical framework will aim to prove performance guarantees for Bayesian prediction algorithms and inform the design of algorithms with desirable properties. The project will contribute to basic scientific research, advancing core goals in machine learning. The project will support training and research of PhD students and therefore will directly support human development. Through classroom teaching and outreach the project will expose a larger population of students to machine learning and its potential in applications.&lt;br/&gt;&lt;br/&gt;More concretely, the project will investigate non-conjugate Bayesian latent variable models, i.e., it will avoid the often used but limiting simplifying assumption of conjugacy. On the algorithmic side the project will aim to generalize the paradigm of variational message passing for non-conjugate graphical models, and to develop stochastic variational inference algorithms using optimal structured approximations for large sub-families of such models. The proposed sub-families will capture the properties of many important problems in the literature. Exploratory research in several specific applications further motivates the work and will be used to test the algorithms. The project will develop a new angle for theoretical analysis of Bayesian algorithms, deriving performance guarantees on their expected error. A core idea is to view variational inference algorithms through the so-called agnostic learning framework where guarantees sought are relative to the best that can be done within a specific limited class of approximations. This will provide a fresh outlook that informs the design of algorithms with desired performance guarantees. The expected scientific impact of the project is having better algorithms with well understood performance characteristics and applicable for a larger class of machine learning problems.</AbstractNarration>
<MinAmdLetterDate>07/27/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1714440</AwardID>
<Investigator>
<FirstName>Roni</FirstName>
<LastName>Khardon</LastName>
<EmailAddress>roni@cs.tufts.edu</EmailAddress>
<StartDate>07/27/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Tufts University</Name>
<CityName>Boston</CityName>
<ZipCode>021111817</ZipCode>
<PhoneNumber>6176273696</PhoneNumber>
<StreetAddress>136 Harrison Ave</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<ProgramElement>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
