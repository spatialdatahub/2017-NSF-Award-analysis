<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Group Travel Award for 2017 Workshop on Learning Perception and Control for Autonomous Flight: Safety, Memory, and Efficiency</AwardTitle>
<AwardEffectiveDate>04/15/2017</AwardEffectiveDate>
<AwardExpirationDate>03/31/2019</AwardExpirationDate>
<AwardAmount>12000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Weng-keen Wong</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Aerial robots, commonly referred to as drones, offer promise in several research, educational, defense and commercial applications.  Some examples include precise agriculture, aerial photography, agile inspection and monitoring, and package delivery.  In most of those applications that aerial robots have started venturing outside the research lab and into the real world, robot operation is often semi-autonomous.  Semi-autonomous operation typically assumes availability of GPS signal for localization, and at least some prior information about the working environment. Sensory-based, fully autonomous operation in unknown environments remains mostly at the research stage.  Yet, endowing full autonomy to aerial robots can enhance their impact on the nation's education, economy, and defense.  To this end, it is important to seamlessly merge perception, planning, and control for autonomous robotic flight in unknown environments.  This can be achieved by integrating machine learning tools into aerial robot perception and control.  Deep learning has recently emerged as a promising way to extract semantic meaning for autonomy.  Learning perception and control for autonomous flight can be approached by replacing hand-engineered map representations with raw sensor observations, and learning appropriate responses.  However, this is not a straightforward task, and several challenges remain.  This workshop critically addresses how to i) best incorporate memory and ii) derive safety guarantees for the learning-based system.  These two aspects are necessary to improve the capacity of aerial robots to operate autonomously in unknown environments, and to push forward the current state-of-the-art in robotic flight.  In addition to the domain of robotic flight, the outcomes of this workshop are relevant to endowing autonomy in general robotic systems that are able to learn, thus helping make autonomous robots ubiquitous.&lt;br/&gt;&lt;br/&gt;The objective of this workshop is to address the theoretical and technical challenges faced in order to endow learning-based systems with the capacity to operate autonomously in unknown environments.  A critical step in this effort is to understand how memory-augmented autonomous learners can operate with provable safety guarantees.  The workshop thus examines two highly-relevant questions.  i) How to theoretically analyze the data and structure of learning-based systems to provide guarantees on safety and task success?  ii) What is the effect of long-term memory and, in particular, can recurrent connections or dynamic external memory replace global map information?  The workshop seeks answers to these questions by bringing together experts from robot planning and control, reinforcement learning and deep learning, and formal methods. The workshop also solicits participation of contributed authors working in relevant areas.  These include but are not limited to applying deep reinforcement learning for vision-based control of underactuated robots; learning visuomotor policies and deriving formal guarantees for learning based on neural networks; and developing neural network architectures that involve temporal recurrence and memory.  The above questions are asked here in the context of high-speed aerial robot autonomous navigation.  However, their scope can be generalized to other areas of robotics that learning perception and control for autonomous operation in unknown environments is desirable; examples include manipulation and legged locomotion.</AbstractNarration>
<MinAmdLetterDate>06/05/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/05/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1743262</AwardID>
<Investigator>
<FirstName>Konstantinos</FirstName>
<LastName>Karydis</LastName>
<EmailAddress>kkarydis@ece.ucr.edu</EmailAddress>
<StartDate>06/05/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Riverside</Name>
<CityName>RIVERSIDE</CityName>
<ZipCode>925210217</ZipCode>
<PhoneNumber>9518275535</PhoneNumber>
<StreetAddress>Research &amp; Economic Development</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7556</Code>
<Text>CONFERENCE AND WORKSHOPS</Text>
</ProgramReference>
</Award>
</rootTag>
